# Prediction of LOS


## Описание проекта

Планирование ресурсов играет важную роль в обеспечении качественного медицинского обслуживания. Для медицинских организаций ключевым вопросом эффективного управления ресурсами представляется компромисс между качеством услуг и затратами: существует желание минимизировать затраты, не ухудшив качество медицинских услуг. Данный компромисс можно достигнуть разными способами: за счет улучшение управления персоналом, а также планирование приема пациентов. При этом остается проблема эффективного использования ресурсов: при низком уровне данного показателя деньги налогоплательщиков не используются на должном уровне, а при высокое использования ресурсов может привести к низкому качеству медицинского обслуживания. 

Важную роль в определении эффективности использования ресурсов влияет время пребывания пациента в больнице (англ. *Length of stay или LOS*). Предсказывание данного показателя позволит поликлиникам рассчитывать даты выписки поступающих пациентов, что в свою очередь позволит улучшить планирование приемов пациентов и эффективному использованию больничных коек. Также прогнозирование LOS позволяет планировать ресурсы в долгосрочной перспективе.
Таким образом, целью данного исследования является рассмотрение влияния пары метод машинного обучения и метод кодирования категориальных признаков на значение выбранной метрики при различных подходах валидации данных. 

## Параметры моделей
| Название модели| Параметры|
|:---:|:---|
|Метод кодирования| 	'n_jobs': -1|
| LinearRegression|  - |
|	KNeighborsRegressor| "n_neighbors": 45, 'n_jobs': -1 |
|	DecisionTreeRegressor| "random_state": 42, 'max_features':'auto'|
|	RandomForestRegressor	| "n_estimators": 100, "random_state": 42, 'n_jobs': -1 |
| MLPRegressor (sklearn)| "hidden_layer_sizes": (32, 32, 64), "solver":'adam', "learning_rate_init": 0.02, "random_state": 42,'early_stopping': True|
|LGBMRegressor (XGBoost)| "metrics": "MSE", "n_estimators": 5000, "learning_rate": 0.02, "random_state": 42, 'n_jobs':- 1|


## Дерево проекта:

Prediction-of-LOS/<br />
|-- models.py<br />
|-- encoders.py<br />
|-- model.py  
|-- experiment.py  
|-- Data_preprocessing.ipynb  
|-- Experiment_results.ipynb  
|-- prep_data/  
|||||-- mimic.csv  
|-- raw_data/  
|||||-- images/  
|||||-- mimic-iii-clinical-database-1.4/  

## Описание файлов:
1. Models.py представляет собой файл с расширением .py и содержит в себе описанные ранее алгоритмы для машинного обучения, которые будут использоваться в эксперименте.
2. Методы кодирования и методы кросс-валидации содержатся в файле encoders.py.
3. Для того чтобы не писать для каждой пары метод кодирования и метод машинного обучения собственный метод напишем унифицированную функцию. Данная функция принимает название метода машинного обучения, реализацию которого находится в файле models.py, название метода кодирования категориальных признаков, который описан в файле encoders.py, а также название метода кросс-валидации, реализацию которого также находится в файле encoders.py. Данную функцию разместим в файле model.py. Также в этом файле будет находиться реализация обучения (метод fit) и предсказания (predict). 
4. Перед тем как начать эксперимент данные проходят процесс предобработки в файле Data_preprocessing.ipynb. Данный файл представляет собой интерес с той точки зрения, что можно просматривать анализ и визуализацию данных, проделанный в предыдущей главе. 
5. Данные, которые участвуют в анализе и визуализации, находятся в папке raw_data, также в этой папке находятся графики, которые были получены в ходе исследования данных. В конце данного файла находится функция, которая приводит данные к единому формату для последующего эксперимента. 
6. Обработанные данные хранятся в папке prep_data.
7. Файл под названием experiment.py содержит эксперимент. Данный файл содержит функцию, позволяющую передать названия моделей и их параметры, название метода кросс-валидации, а также список методов кодирования категориальных признаков, которые будут применены к данным. В результате получается словарь, состоящий из полученных результатов. 
8. Результаты полученного эксперимента хранятся в папке results. Файлы, которые хранятся в этой папке, имеют следующий вид: {название датасета}_{название метода кросс-валидации}.csv. 
9. Наконец, результаты эксперимента можно просмотреть в файле Experiment_results.ipynb.

## Последовательность файлов для воспроизведения эксперимента

1. Data_preprocessing.ipynb
2. experiment.py
3. Experiment_results.ipynb

<<<<<<< HEAD

## Результаты на тестовой выборке


### Validation type: None
|Метод кодирования|LinearRegression|	KNeighborsRegressor|	DecisionTreeRegressor|	RandomForestRegressor	|MLPRegressor	|LGBMRegressor|
|:---:|:---:|:---:| :---:|:---:|:---:| :---:|
|BackwardDifferenceEncoder	| **83.886**	| *114.397*	| 253.053	| 113.014	| 116.766	|85.3485|
|FrequencyEncoder|	79.5718|	115.378|	253.572|	85.255|	116.483	|**74.9897**|
|HelmertEncoder|	77.3658|	*114.397*|	221.148|	86.3063	|*79.4962* |**76.0341**|
|JamesSteinEncoder|**83.7425**|*114.397*|398.701|111.25|122.172|87.6164|
|LeaveOneOutEncoder|**81.3309**|*114.397*|*118.17*|117.894|83.5761|117.53|
|MEstimateEncoder|**83.3314**|*114.397*|398.701|111.25|85.9935|87.6164|
|OneHotEncoder|**83.886**|*114.397*|229.358|95.6498|116.733|84.8071|
|OrdinalEncoder|100.181|*114.397*|268.801|*85.0247*|85.2655|85.7505|
|SumEncoder|*77.3658*|*114.397*|245.434|86.7759|89.2989|*74.8041*|
|TargetEncoder|**83.3319**|114.397|398.701|111.25|101.237|87.6164|

### Validation type: Single
|Метод кодирования|LinearRegression|	KNeighborsRegressor|	DecisionTreeRegressor|	RandomForestRegressor	|MLPRegressor	|LGBMRegressor|
|:---:|:---:|:---:| :---:|:---:|:---:| :---:|
|BackwardDifferenceEncoder|77.3658|*114.397*|239.393|*84.494*|117.735|**75.9018**|
|CatBoostEncoder| 80.7028|*114.397*|219.27|85.4648|104.588|**73.4174**|
|FrequencyEncoder| 79.5648|115.323|253.588|85.2524|116.338|**74.9897**|
|HelmertEncoder| 77.3658|*114.397*|228.985|86.3876|115.005|**74.2031**|
|JamesSteinEncoder| 81.6168|*114.397*|222.607|84.8551|191.12|**76.5161**|
|LeaveOneOutEncoder| **81.2863**|*114.397*|*118.238*|118.009|111.164|117.643|
|MEstimateEncoder| 81.2353|*114.397*|210.099|86.7404|*75.8812*|**74.9903**|
|OneHotEncoder| 77.3658|*114.397*|247.186|86.0236|99.3873|**74.8041**|
|OrdinalEncoder| 80.2765|114.397|229.016|84.8798|109.886|75.3688|
|SumEncoder|*77.3658*|114.397|244.34|86.3527|206.386|**74.8041**|
|TargetEncoder| 81.237|*114.397*|210.099|86.7404|87.4663|**74.9903**|

* *Курсивом* выделен лучший скор на методе машиннного обучения 
* **Жирным шрифтом** выделен лучшиий скор на методе кодирования категориальных признаков

### Validation type: Double
|Метод кодирования|LinearRegression|	KNeighborsRegressor|	DecisionTreeRegressor|	RandomForestRegressor	|MLPRegressor	|LGBMRegressor|
|:---:|:---:|:---:| :---:|:---:|:---:| :---:|
|CatBoostEncoder| 81.2803|*114.397*|227.465|*79.5997*|80.3438|**71.7553**|
|FrequencyEncoder| **81.1614**|114.976|419.356|116.292|118.662|88.2224|
|JamesSteinEncoder| 81.6414|*114.397*|*206.091*|80.2682|*78.4088*|**73.2844**|
|LeaveOneOutEncoder| 81.2807|*114.397*|244.362|79.6565|107.507|**72.6443**|
|MEstimateEncoder| 81.2803|*114.397*|227.465|**79.5997*|80.3438|**71.7553**|
|TargetEncoder| 81.2815|*114.397*|244.362|79.6565|92.6553|72.6443|

## Выводы
Подводя выводы по всем подходам валидации данных с категориальными признаками можно сделать следующие выводы:
1.	Методы, которые не используют информацию о значениях целевой переменной, показывают хорошие результаты метрики в подходе None Validation: SumEncoder, HelmertEncoder, OrdinalEncoder.
2.	Методы, использующие информацию о значениях целевой переменной, показывают хорошие результаты метрики в подходе Single Validation: CatBoostEncoder, LeaveOneOutEncoder, MEstimateEncoder.
3.	Подход Double Validation совместно с методами кодирования категориальных признаков – CatBoostEncoder, JamesSteinEncoder, MEstimateEncoder – показывают улучшение значений метрик, по сравнению с подходом Single Validation. Таким образом, такой подход может улучшить значения метрики.
4.	Несмотря на хорошие результаты One-Hot кодирования, применение иных подходов может показать значительное снижение результатов метрики. При этом, SumEncoder, который представляет собой изменение One-Hot кодирования, может показывать значения метрики не хуже One-Hot кодирования, а в некоторых случаях значения метрики лучше.
5.	Наилучшим алгоритмов при для предсказания времени пребывания в больнице является градиентный бустинг. Однако, стоит учитывать, что нейронная сеть в эксперименте представляет собой трехслойную  полносвязную сеть и показатели метрики могут быть улучшены при оптимизации гиперпараметров. 



=======
>>>>>>> 7880fb99b4d0cfff90ab374656b6ab61e3e2f5b1
### Основные источники
1. [Predicting hospital length-of-stay at time of admission](https://towardsdatascience.com/predicting-hospital-length-of-stay-at-time-of-admission-55dfdfe69598) [git](https://github.com/DenisVorotyntsev/CategoricalEncodingBenchmark)
2. [Benchmarking Categorical Encoders](https://towardsdatascience.com/benchmarking-categorical-encoders-9c322bd77ee8) [git](https://towardsdatascience.com/predicting-hospital-length-of-stay-at-time-of-admission-55dfdfe69598)
